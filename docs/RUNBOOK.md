# Operations Runbook

**Schnittwerk Web Application - Operations Guide**

Version: 0.1.0  
Last Updated: 2024-11-06  
Owner: DevOps

---

## Table of Contents

1. [Quick Reference](#quick-reference)
2. [Deployment](#deployment)
3. [Monitoring](#monitoring)
4. [Incident Response](#incident-response)
5. [Maintenance](#maintenance)
6. [Troubleshooting](#troubleshooting)
7. [Disaster Recovery](#disaster-recovery)

---

## Quick Reference

### Essential Links

**Production**

- Website: https://www.schnittwerk-vanessa.ch
- Admin: https://www.schnittwerk-vanessa.ch/admin
- Health: https://www.schnittwerk-vanessa.ch/api/health
- Status: https://vercel.com/[project]/deployments

**Monitoring**

- Sentry: https://sentry.io/organizations/schnittwerk/
- Vercel Analytics: https://vercel.com/[project]/analytics
- Plausible: https://plausible.io/schnittwerk-vanessa.ch
- Supabase Dashboard: https://app.supabase.com/project/[id]

**Development**

- GitHub: https://github.com/[org]/schnittwerk
- CI/CD: https://github.com/[org]/schnittwerk/actions

### Emergency Contacts

**On-Call Rotation** (To be defined)

- Primary: [Name, Phone, Email]
- Secondary: [Name, Phone, Email]
- Escalation: [Name, Phone, Email]

**Service Providers**

- Vercel Support: https://vercel.com/help
- Supabase Support: support@supabase.io
- Resend Support: support@resend.com

### Critical Commands

```bash
# Check application status
curl https://www.schnittwerk-vanessa.ch/api/health

# Check readiness
curl https://www.schnittwerk-vanessa.ch/api/ready

# Deploy to production (via GitHub)
git tag v1.0.0
git push origin v1.0.0

# Rollback deployment (Vercel)
# Use Vercel dashboard to promote previous deployment

# View logs (Vercel CLI)
vercel logs [deployment-url]

# Database backup (Supabase)
# Automated daily, manual via Supabase dashboard
```

---

## Deployment

### Environments

**Development**

- Branch: `main` (local development)
- Deploy: Manual (`pnpm dev`)
- Database: Local or Supabase dev project
- URL: http://localhost:3000

**Preview**

- Branch: Any PR branch
- Deploy: Automatic on PR
- Database: Supabase preview branch
- URL: Auto-generated by Vercel
- Purpose: Testing, review

**Staging**

- Branch: `develop`
- Deploy: Automatic on push
- Database: Supabase staging
- URL: https://staging.schnittwerk-vanessa.ch
- Purpose: QA, client review

**Production**

- Branch: `main` (protected)
- Deploy: Automatic on release tag
- Database: Supabase production
- URL: https://www.schnittwerk-vanessa.ch
- Purpose: Live system

### Deployment Process

**Standard Release**

1. Merge feature PR to `develop`
2. Deploy to staging automatically
3. Run smoke tests
4. QA approval
5. Merge `develop` to `main`
6. Create release tag: `git tag v1.x.x`
7. Push tag: `git push origin v1.x.x`
8. Automatic deployment to production
9. Run smoke tests on production
10. Monitor for 30 minutes

**Hotfix Release**

1. Branch from `main`: `hotfix/description`
2. Implement fix
3. Test locally
4. Create PR to `main`
5. Expedited review
6. Merge and tag
7. Deploy
8. Monitor closely
9. Backport to `develop`

**Rollback**

1. Access Vercel dashboard
2. Find previous stable deployment
3. Click "Promote to Production"
4. Deployment switched instantly
5. Investigate issue
6. Fix and redeploy properly

### Database Migrations

**Development**

```bash
# Generate migration
pnpm --filter @schnittwerk/db db:generate

# Review SQL in packages/db/migrations
# Test migration
pnpm --filter @schnittwerk/db db:migrate
```

**Staging/Production**

```bash
# Migrations run automatically in CI/CD
# Before application deployment
# Check CI logs for migration status

# Manual migration (emergency only)
DATABASE_URL=<prod-url> pnpm --filter @schnittwerk/db db:migrate
```

**Migration Checklist**

- [ ] Migration tested locally
- [ ] Migration is reversible (or forward-only documented)
- [ ] Data migration tested with prod data copy
- [ ] Indexes added for new queries
- [ ] RLS policies updated
- [ ] Backup taken before migration
- [ ] Rollback plan documented

---

## Monitoring

### Health Checks

**Endpoints**

- `/api/health`: Basic liveness (200 = OK)
- `/api/ready`: Readiness with dependencies (200 = ready, 503 = not ready)

**Monitoring Frequency**

- External: Every 1 minute (Uptime Robot or similar)
- Internal: Every 30 seconds (Kubernetes/Vercel)

**Alerting**

- Health check fails 3 times in a row â†’ Page on-call
- Readiness check fails â†’ Investigate, may self-recover
- Both failing â†’ Critical incident

### Key Metrics

**Application**

- Response time (p50, p95, p99)
- Error rate (4xx, 5xx)
- Request rate (requests per second)
- Booking conversion rate
- Payment success rate

**Infrastructure**

- CPU usage
- Memory usage
- Database connections
- Redis cache hit rate

**Business**

- Active users
- Bookings per day
- Orders per day
- Revenue (daily, weekly, monthly)

### Dashboards

**Vercel Analytics**

- Web Vitals (LCP, FID, CLS)
- Page views and unique visitors
- Top pages
- Geography

**Sentry**

- Error rate by page
- User impact
- Release comparison
- Performance issues

**Plausible**

- Traffic sources
- Top pages
- Conversion goals
- Bounce rate

**Supabase**

- Database size
- Query performance
- Connection pool usage
- Replication lag (if applicable)

### Alerts

**Critical (Page immediately)**

- Service down (health checks failing)
- Error rate >5%
- Payment processing failures >10%
- Database connection errors

**High (Notify within 15 min)**

- Error rate >1%
- Response time p95 >3s
- Database query slow (>1s)
- Disk usage >80%

**Medium (Notify within 1 hour)**

- Error rate >0.1%
- Cache hit rate <70%
- Unusual traffic patterns
- Background job failures

**Low (Daily digest)**

- Warning logs increased
- Deprecated API usage
- Certificate expiring in 30 days

---

## Incident Response

### Severity Levels

**P0 - Critical**

- Service completely unavailable
- Data breach or loss
- Payment system down
- Impact: All users
- Response: Immediate (page on-call)
- SLA: Acknowledge <15 min, Resolve <4 hours

**P1 - High**

- Major feature broken
- Performance severely degraded
- Security vulnerability
- Impact: Many users
- Response: <30 minutes
- SLA: Acknowledge <30 min, Resolve <24 hours

**P2 - Medium**

- Minor feature broken
- Isolated errors
- Performance degraded
- Impact: Some users
- Response: <2 hours
- SLA: Resolve <72 hours

**P3 - Low**

- Cosmetic issues
- Enhancement requests
- Documentation errors
- Impact: Minimal
- Response: Next business day
- SLA: Resolve <1 week

### Incident Workflow

**1. Detection**

- Monitoring alert
- User report
- Team member discovery

**2. Triage**

- Assess severity
- Assign owner
- Create incident ticket
- Start war room (P0/P1)

**3. Investigation**

- Check health endpoints
- Review error logs (Sentry)
- Check recent deployments
- Check database status
- Review metrics/dashboards

**4. Communication**

- Internal: Slack incident channel
- External: Status page update
- Stakeholders: Email/phone as needed

**5. Mitigation**

- Rollback deployment (if recent release)
- Disable problematic feature (feature flag)
- Scale resources (if capacity issue)
- Apply hotfix

**6. Resolution**

- Verify fix in staging
- Deploy to production
- Monitor for 30 minutes
- Confirm with users

**7. Post-Mortem**

- Timeline of events
- Root cause analysis
- What went well / What didn't
- Action items (preventive measures)
- Share with team within 48 hours

### Communication Templates

**Incident Start**

```
ðŸ”´ INCIDENT: [Brief description]
Severity: P0/P1/P2/P3
Impact: [User impact]
Owner: [Name]
Status: Investigating
Started: [Time]
Updates: Will post every 15/30/60 minutes
```

**Incident Update**

```
ðŸ“Š UPDATE: [Incident name]
Status: [Investigating/Mitigating/Resolved]
Actions taken: [What we did]
Next steps: [What's next]
ETA: [If known]
Updated: [Time]
```

**Incident Resolved**

```
âœ… RESOLVED: [Incident name]
Duration: [Start - End]
Resolution: [What fixed it]
Root cause: [Brief]
Post-mortem: [Link] (within 48h)
Resolved: [Time]
```

---

## Maintenance

### Regular Tasks

**Daily**

- Check error rates (Sentry)
- Review failed background jobs
- Monitor disk usage
- Check backup status

**Weekly**

- Review performance metrics
- Check certificate expiration
- Update dependencies (review)
- Review security advisories

**Monthly**

- Dependency updates (apply)
- Database performance review
- Cost optimization review
- Rotate API keys (if policy requires)
- Review and archive old logs

**Quarterly**

- Full security audit
- Disaster recovery drill
- Capacity planning review
- Documentation review
- Third-party service review

**Annually**

- Penetration testing
- SSL certificate renewal
- DPA renewals
- Compliance audit
- Incident response plan review

### Backup Strategy

**Database Backups**

- Frequency: Daily (automated by Supabase)
- Retention: 7 days (point-in-time recovery)
- Long-term: Weekly backups retained for 3 months
- Location: Supabase S3-compatible storage
- Encryption: Yes (AES-256)

**Testing Backups**

- Monthly: Restore to staging and verify
- Quarterly: Full disaster recovery drill

**Application Code**

- Version control: Git (GitHub)
- Retention: Indefinite
- Redundancy: GitHub's infrastructure

**Secrets**

- Backup: Encrypted and stored offline
- Access: Limited to key personnel
- Rotation: Quarterly or on personnel changes

### Dependency Updates

**Policy**

- Security updates: Within 48 hours
- Minor updates: Monthly
- Major updates: Quarterly (with testing)

**Process**

1. Review changelog
2. Update in development
3. Run full test suite
4. Deploy to staging
5. QA approval
6. Deploy to production
7. Monitor for issues

**Tools**

- Dependabot (GitHub)
- `pnpm audit`
- `pnpm outdated`

---

## Troubleshooting

### Common Issues

**Issue: Application Not Loading**

**Symptoms**: 502/503 errors, health check failing

**Diagnosis**

1. Check Vercel deployment status
2. Check health endpoint: `curl /api/health`
3. Review recent deployments
4. Check Sentry for errors
5. Check database connectivity

**Resolution**

- If recent deployment: Rollback
- If database issue: Check Supabase status
- If Vercel issue: Check Vercel status page
- If cache issue: Clear Redis

---

**Issue: Slow Response Times**

**Symptoms**: High p95/p99 latency, timeouts

**Diagnosis**

1. Check Vercel Analytics
2. Review Sentry performance
3. Check database slow queries (Supabase)
4. Check Redis cache hit rate
5. Review recent code changes

**Resolution**

- Add database indexes
- Optimize queries (N+1 issues)
- Increase cache TTL
- Implement pagination
- Scale Vercel function size

---

**Issue: Payment Failures**

**Symptoms**: Users reporting failed payments, Sentry errors

**Diagnosis**

1. Check SumUp/Stripe status page
2. Review webhook logs
3. Check API key validity
4. Review payment error logs
5. Test payment flow manually

**Resolution**

- If provider issue: Switch to fallback (Stripe)
- If webhook issue: Replay failed webhooks
- If key issue: Rotate keys and update
- If code issue: Hotfix and deploy

---

**Issue: Database Connection Errors**

**Symptoms**: `ECONNREFUSED`, `too many connections`

**Diagnosis**

1. Check Supabase dashboard
2. Review connection pool settings
3. Check for connection leaks
4. Monitor active connections

**Resolution**

- Increase connection pool size
- Fix connection leaks in code
- Restart application
- Scale database if necessary

---

**Issue: High Error Rate**

**Symptoms**: Sentry alert, 4xx/5xx errors spike

**Diagnosis**

1. Check Sentry for error patterns
2. Review recent deployments
3. Check for bad user input
4. Review API changes
5. Check third-party service status

**Resolution**

- If code bug: Hotfix
- If bad input: Add validation
- If third-party: Wait or disable feature
- If deployment: Rollback

---

### Debugging Tools

**Logs**

```bash
# View production logs (Vercel CLI)
vercel logs --follow

# Filter by status code
vercel logs --follow | grep "500"

# View specific deployment
vercel logs [deployment-url]
```

**Database**

```bash
# Connect to database (Supabase)
psql $DATABASE_URL

# Check slow queries
SELECT query, calls, mean_exec_time
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;

# Check active connections
SELECT count(*) FROM pg_stat_activity;
```

**Health Check**

```bash
# Basic health
curl https://www.schnittwerk-vanessa.ch/api/health

# Readiness with details
curl https://www.schnittwerk-vanessa.ch/api/ready | jq
```

---

## Disaster Recovery

### Scenarios

**Scenario 1: Complete Data Loss**

**Recovery Steps**

1. Declare disaster
2. Create new Supabase project
3. Restore from most recent backup
4. Restore application code from Git
5. Update environment variables
6. Run smoke tests
7. Update DNS (if needed)
8. Notify users

**RPO**: 24 hours (daily backups)  
**RTO**: 4 hours

---

**Scenario 2: Vercel Outage**

**Recovery Steps**

1. Monitor Vercel status
2. If prolonged: Prepare alternative deployment
3. Deploy to fallback (e.g., Railway, Fly.io)
4. Update DNS
5. Test thoroughly
6. Notify users

**RPO**: N/A (code in Git)  
**RTO**: 8 hours (preparation needed)

---

**Scenario 3: Data Breach**

**Response Steps**

1. Isolate affected systems
2. Assess scope of breach
3. Notify authorities (FDPIC) within 72 hours
4. Notify affected users
5. Implement remediation
6. Conduct forensic analysis
7. Update security measures
8. Document lessons learned

**Required Time**: As per GDPR/DSG (72 hours)

---

### Backup and Restore

**Full System Backup**

- Database: Automated daily (Supabase)
- Application: Git repository
- Secrets: Encrypted offline storage
- Configuration: Infrastructure as Code (IaC)

**Restore Procedure**

1. Create new environment
2. Restore database from backup
3. Deploy application code
4. Restore secrets to environment
5. Run migrations
6. Verify integrity
7. Switch traffic

**Testing**

- Quarterly disaster recovery drill
- Documented in runbook
- Timed and measured against RTO

---

## Appendix

### Useful SQL Queries

```sql
-- Find slow queries
SELECT query, calls, mean_exec_time, max_exec_time
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 20;

-- Check table sizes
SELECT schemaname, tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename))
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- Check index usage
SELECT schemaname, tablename, indexname, idx_scan
FROM pg_stat_user_indexes
WHERE idx_scan = 0
AND indexname NOT LIKE 'pg_toast%'
ORDER BY pg_relation_size(indexrelid) DESC;

-- Active connections
SELECT datname, usename, application_name, state, count(*)
FROM pg_stat_activity
GROUP BY datname, usename, application_name, state
ORDER BY count(*) DESC;
```

### Environment Variables Reference

See `.env.example` for complete list.

**Critical Variables**

- `DATABASE_URL`: PostgreSQL connection string
- `SUPABASE_SERVICE_ROLE_KEY`: Admin access to database
- `SENTRY_DSN`: Error tracking
- `SUMUP_CLIENT_SECRET`: Payment processing
- `STRIPE_SECRET_KEY`: Payment fallback

**Rotation Schedule**

- API keys: Quarterly or on breach
- Database passwords: Annually or on staff change
- JWT secrets: Only on breach

---

**Last Updated**: 2024-11-06  
**Next Review**: 2025-02-06  
**Owner**: DevOps Team

**Emergency Contact**: [To be added in production]
